{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "import vansy_f8a_genai_test.report_a03_rag_and_reasoning_frameworks_tutorial_prompt as prompt_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=5,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital Cypher Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")\n",
    "\n",
    "graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_generation_template = prompt_hub.CYPHER_GENERATION_TEMPLATE\n",
    "qa_generation_template = prompt_hub.QA_GENERATION_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], template=cypher_generation_template\n",
    ")\n",
    "\n",
    "qa_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], template=qa_generation_template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    cypher_llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
    "    qa_llm=ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    qa_prompt=qa_generation_prompt,\n",
    "    cypher_prompt=cypher_generation_prompt,\n",
    "    validate_cypher=True,\n",
    "    top_k=100,\n",
    "    allow_dangerous_requests=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent, Tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wrap your chain in the Tool class\n",
    "hospital_tool = Tool(\n",
    "    name=\"HospitalGraphQA\",\n",
    "    # The 'func' is the chain's invoke method. We use a lambda to map the\n",
    "    # string input from the agent to the dictionary input the chain expects.\n",
    "    func=lambda q: hospital_cypher_chain.invoke({\"query\": q}),\n",
    "    description=\"\"\"Useful for answering questions about patients,\n",
    "        physicians, hospitals, insurance payers, patient review\n",
    "        statistics, and hospital visit details. Use the entire prompt as\n",
    "        input to the tool. For instance, if the prompt is 'How many visits\n",
    "        have there been?\", the input should be \"How many visits have\n",
    "        there been?'\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the tools for agent can use\n",
    "tools = [hospital_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vansy/Documents/Projects/vansy-f8a-genai-test/.venv/lib/python3.13/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 3. Set up the ReAct Agent\n",
    "# Pull the standard ReAct prompt\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'input_variables': ['agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
       " 'optional_variables': [],\n",
       " 'output_parser': None,\n",
       " 'partial_variables': {},\n",
       " 'metadata': {'lc_hub_owner': 'hwchase17',\n",
       "  'lc_hub_repo': 'react',\n",
       "  'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'},\n",
       " 'tags': None,\n",
       " 'template': 'Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}',\n",
       " 'template_format': 'f-string',\n",
       " 'validate_template': False,\n",
       " '_type': 'prompt'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [{tool_names}]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt_template = \"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "PREVIOUS CHAT HISTORY:\n",
    "{chat_history}\n",
    "\n",
    "NEW QUESTION:\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=['chat_history','agent_scratchpad', 'input', 'tool_names', 'tools'],\n",
    "    template=custom_prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM for the agent to use\n",
    "# This can be the same or different from the models in your chain\n",
    "agent_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "agent = create_react_agent(agent_llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent executor to run the agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat with the Hospital AI Agent! Type 'exit' to quit.\n",
      "\n",
      "User: How many visits were there at 'Jones, Brown and Murray'?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: HospitalGraphQA  \n",
      "Action Input: How many visits were there at 'Jones, Brown and Murray'?  \u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (h:Hospital {name: 'Jones, Brown and Murray'})<-[:AT]-(v:Visit)\n",
      "RETURN COUNT(v) AS visit_count\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'visit_count': 317}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m{'query': \"How many visits were there at 'Jones, Brown and Murray'?\", 'result': \"There were 317 visits at 'Jones, Brown and Murray'.\"}\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: There were 317 visits at 'Jones, Brown and Murray'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Agent: There were 317 visits at 'Jones, Brown and Murray'.\n",
      "\n",
      "User: exit\n",
      "\n",
      "Agent: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# --- 4. The Interactive Chat Loop ---\n",
    "print(\"Chat with the Hospital AI Agent! Type 'exit' to quit.\")\n",
    "while True:\n",
    "    try:\n",
    "        user_question = input(\"You: \")\n",
    "        print(f\"\\nUser: {user_question}\")\n",
    "        if user_question.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"\\nAgent: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Invoke the agent executor with the user's question\n",
    "        response = agent_executor.invoke({\"input\": user_question})\n",
    "        \n",
    "        # Print the final answer\n",
    "        print(f\"\\nAgent: {response['output']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
